{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae161a5d",
   "metadata": {
    "papermill": {
     "duration": 0.007593,
     "end_time": "2026-01-15T13:46:20.554117",
     "exception": false,
     "start_time": "2026-01-15T13:46:20.546524",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Importing Dependancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1725f4a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T13:46:20.568327Z",
     "iopub.status.busy": "2026-01-15T13:46:20.567710Z",
     "iopub.status.idle": "2026-01-15T13:46:34.148366Z",
     "shell.execute_reply": "2026-01-15T13:46:34.147461Z"
    },
    "papermill": {
     "duration": 13.590119,
     "end_time": "2026-01-15T13:46:34.150525",
     "exception": false,
     "start_time": "2026-01-15T13:46:20.560406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sqlalchemy/orm/query.py:195: SyntaxWarning: \"is not\" with 'tuple' literal. Did you mean \"!=\"?\n",
      "  if entities is not ():\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from catboost import CatBoostRegressor\n",
    "from scipy import stats\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.ensemble import (\n",
    "    GradientBoostingRegressor,\n",
    "    RandomForestRegressor,\n",
    "    StackingRegressor,\n",
    "    VotingRegressor,\n",
    ")\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import ElasticNet, Lasso, LinearRegression, Ridge\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, root_mean_squared_error\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    KFold,\n",
    "    cross_val_score,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33af167d",
   "metadata": {
    "papermill": {
     "duration": 0.006139,
     "end_time": "2026-01-15T13:46:34.163134",
     "exception": false,
     "start_time": "2026-01-15T13:46:34.156995",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loading our CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39e82ed5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T13:46:34.178402Z",
     "iopub.status.busy": "2026-01-15T13:46:34.177731Z",
     "iopub.status.idle": "2026-01-15T13:46:34.202020Z",
     "shell.execute_reply": "2026-01-15T13:46:34.200790Z"
    },
    "papermill": {
     "duration": 0.033506,
     "end_time": "2026-01-15T13:46:34.203697",
     "exception": true,
     "start_time": "2026-01-15T13:46:34.170191",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/kobey/Documents/DATASCIENCE/PROJECTS/CALIFORNIA HOUSING PRICES/data/02-preprocessed/preprocessed.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17/3758816050.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m final_housing_df = pd.read_csv(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"/home/kobey/Documents/DATASCIENCE/PROJECTS/CALIFORNIA HOUSING PRICES/data/02-preprocessed/preprocessed.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      4\u001b[0m \u001b[0mfinal_housing_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/kobey/Documents/DATASCIENCE/PROJECTS/CALIFORNIA HOUSING PRICES/data/02-preprocessed/preprocessed.csv'"
     ]
    }
   ],
   "source": [
    "final_housing_df = pd.read_csv(\n",
    "    \"/home/kobey/Documents/DATASCIENCE/PROJECTS/CALIFORNIA HOUSING PRICES/data/02-preprocessed/preprocessed.csv\"\n",
    ")\n",
    "final_housing_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e62d7b1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Train, Test and Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e3ce4d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = final_housing_df[\"median_house_value\"]\n",
    "X = final_housing_df.drop(\"median_house_value\", axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab503d6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdd3e1b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Preprocessing to change the scale of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ed52c6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de47565",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "numeric_col = X_train.columns[:8]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train[numeric_col])\n",
    "\n",
    "\n",
    "def preprocessor(X):\n",
    "    X_copy = X.copy()\n",
    "    X_copy[numeric_col] = scaler.transform(X_copy[numeric_col])\n",
    "    return X_copy\n",
    "\n",
    "\n",
    "X_train_pre, X_test_pre = preprocessor(X_train), preprocessor(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6450bcbe",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(X_train_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b91d1f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(X_train_pre).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a683db",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_pre.shape, X_test_pre.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8d502f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Saving the train and Test dataframes in the 03-features data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2f2bcf",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define folder\n",
    "folder_path = (\n",
    "    \"/home/kobey/Documents/DATASCIENCE/PROJECTS/CALIFORNIA HOUSING PRICES/data/03-features\"\n",
    ")\n",
    "\n",
    "# Make folder if it doesn't exist\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "# Define filenames\n",
    "train_file = os.path.join(folder_path, \"train_preprocessed.csv\")\n",
    "test_file = os.path.join(folder_path, \"test_preprocessed.csv\")\n",
    "\n",
    "# Save preprocessed DataFrames\n",
    "X_train_pre.to_csv(train_file, index=False)\n",
    "X_test_pre.to_csv(test_file, index=False)\n",
    "\n",
    "# Optional: print confirmation\n",
    "print(\"Train and test sets saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc04644",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adc6005",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize and fit model\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train_pre, y_train)\n",
    "\n",
    "# Predict on training set\n",
    "y_pred_train = lm.predict(X_train_pre)\n",
    "\n",
    "# Compute RMSE manually\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "print(\"Train RMSE:\", rmse_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20150681",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## k-fold for Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59090a22",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Step 1 Define RMSE Scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57daf69",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rmse_scorer = make_scorer(root_mean_squared_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8cddaa",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Step 2 Create K-Fold splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4856f2a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f2b83c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Step 3 Evaluate model with CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a45b4c1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "cv_scores = cross_val_score(lm, X_train_pre, y_train, cv=kf, scoring=rmse_scorer)\n",
    "\n",
    "print(\"RMSE for each fold:\", cv_scores)\n",
    "print(\"Mean RMSE:\", cv_scores.mean())\n",
    "print(\"Std RMSE:\", cv_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1062c5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f5fd50",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize and fit model\n",
    "knn = KNeighborsRegressor(n_neighbors=15)\n",
    "knn.fit(X_train_pre, y_train)\n",
    "\n",
    "# Predict on training set\n",
    "y_pred_train = knn.predict(X_train_pre)\n",
    "\n",
    "# Compute RMSE manually\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "print(\"Train RMSE:\", rmse_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0be93fa",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Running cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ab44e4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use the string shortcut\n",
    "knn_scores = cross_val_score(knn, X_train_pre, y_train, scoring=rmse_scorer, cv=10)\n",
    "\n",
    "knn_rmse_scores = -knn_scores  # Flip the sign to make it positive\n",
    "\n",
    "print(\"KNN Cross-Validation Mean RMSE:\", knn_rmse_scores.mean())\n",
    "print(\"KNN Cross-Validation Std:\", knn_rmse_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8594d124",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### run a GridSearchCV to automatically find the best number of neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3909d1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Define the parameter values we want to try\n",
    "param_grid = [{\"n_neighbors\": [2, 5, 10, 25, 35], \"weights\": [\"uniform\", \"distance\"]}]\n",
    "\n",
    "# 2. Set up the search\n",
    "grid_search = GridSearchCV(\n",
    "    KNeighborsRegressor(), param_grid, cv=5, scoring=rmse_scorer, return_train_score=True\n",
    ")\n",
    "\n",
    "# 3. Fit the search (this will take a moment)\n",
    "grid_search.fit(X_train_pre, y_train)\n",
    "\n",
    "# 4. Get the results\n",
    "print(\"Best Params:\", grid_search.best_params_)\n",
    "print(\"Best RMSE:\", -grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea90196",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810d5940",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize and fit model\n",
    "rfr = RandomForestRegressor(max_depth=6)\n",
    "rfr.fit(X_train_pre, y_train)\n",
    "\n",
    "# Predict on training set\n",
    "y_pred_train = rfr.predict(X_train_pre)\n",
    "\n",
    "# Compute RMSE manually\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "print(\"Train RMSE:\", rmse_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5cfb5e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Running cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35fe9f6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Check the \"Real\" performance with Cross Validation\n",
    "rfr_scores = cross_val_score(\n",
    "    rfr, X_train_pre, y_train, scoring=\"neg_root_mean_squared_error\", cv=10\n",
    ")\n",
    "\n",
    "rfr_rmse_scores = -rfr_scores  # Flip sign to positive\n",
    "\n",
    "print(\"Random Forest Cross-Val Mean RMSE:\", rfr_rmse_scores.mean())\n",
    "print(\"Random Forest Cross-Val Std:\", rfr_rmse_scores.std())\n",
    "print(\"Gap (Overfitting):\", rfr_rmse_scores.mean() - rmse_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc10a69c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### run a GridSearchCV to automatically find the best number of max depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bae9b2c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Define the parameters to test\n",
    "# We test specific limits [5, 10, 20] and 'None' (unlimited depth)\n",
    "param_grid = [\n",
    "    {\n",
    "        \"max_depth\": [5, 10, 15, 20, 30, None],\n",
    "        \"n_estimators\": [100],\n",
    "    }  # Keeping estimators constant for now\n",
    "]\n",
    "\n",
    "# 2. Set up the search\n",
    "# n_jobs=-1 uses all your CPU cores to speed up calculation\n",
    "forest_grid_search = GridSearchCV(\n",
    "    RandomForestRegressor(random_state=42),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    return_train_score=True,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# 3. Fit the search\n",
    "forest_grid_search.fit(X_train_pre, y_train)\n",
    "\n",
    "# 4. Results\n",
    "print(\"Best Max Depth:\", forest_grid_search.best_params_[\"max_depth\"])\n",
    "print(\"Best Cross-Val RMSE:\", -forest_grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd65a6f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affb2bef",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gbr = GradientBoostingRegressor(n_estimators=30)\n",
    "gbr.fit(X_train_pre, y_train)\n",
    "\n",
    "# Predict on training set\n",
    "y_pred_train = gbr.predict(X_train_pre)\n",
    "\n",
    "# Compute RMSE manually\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "print(\"Train RMSE:\", rmse_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35704f7a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Run with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c9c318",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Check the \"Real\" performance with Cross Validation\n",
    "gbr_scores = cross_val_score(gbr, X_train_pre, y_train, scoring=rmse_scorer, cv=10)\n",
    "\n",
    "gbr_rmse_scores = -gbr_scores  # Flip sign to positive\n",
    "\n",
    "print(\"Gradient Boosting Cross-Val Mean RMSE:\", gbr_rmse_scores.mean())\n",
    "print(\"Gradient Boosting Cross-Val Std:\", gbr_rmse_scores.std())\n",
    "print(\"Gap (Overfitting):\", gbr_rmse_scores.mean() - rmse_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f83f859",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bb961f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Define the grid\n",
    "# We want to see if 'Slow & Steady' (0.01 + 300) beats 'Fast & Aggressive' (0.3 + 30)\n",
    "param_grid = [\n",
    "    {\n",
    "        \"n_estimators\": [30, 100, 300, 500],\n",
    "        \"learning_rate\": [0.01, 0.1, 0.3],\n",
    "        \"max_depth\": [3],  # Standard default for Boosting is shallow trees (3)\n",
    "    }\n",
    "]\n",
    "\n",
    "# 2. Set up the search\n",
    "gb_grid_search = GridSearchCV(\n",
    "    GradientBoostingRegressor(random_state=42),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring=rmse_scorer,\n",
    "    n_jobs=-1,  # Use all cores\n",
    ")\n",
    "\n",
    "# 3. Fit the search\n",
    "print(\"Running Grid Search... (this may take a minute)\")\n",
    "gb_grid_search.fit(X_train_pre, y_train)\n",
    "\n",
    "# 4. Results\n",
    "print(\"\\n--- Results ---\")\n",
    "print(\"Best Params:\", gb_grid_search.best_params_)\n",
    "print(\"Best Cross-Val RMSE:\", -gb_grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdddbda",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf9580b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "simple_nn = Sequential()\n",
    "# Ensure input_shape matches your data (13 features)\n",
    "simple_nn.add(InputLayer(input_shape=(13,)))\n",
    "simple_nn.add(Dense(2, activation=\"relu\"))\n",
    "simple_nn.add(Dense(1, activation=\"linear\"))\n",
    "\n",
    "opt = Adam(learning_rate=0.1)\n",
    "\n",
    "# FIX: Added .keras extension here\n",
    "cp = ModelCheckpoint(\"models/simple_nn.keras\", save_best_only=True)\n",
    "\n",
    "simple_nn.compile(optimizer=opt, loss=\"mse\", metrics=[RootMeanSquaredError()])\n",
    "simple_nn.fit(x=X_train_pre, y=y_train, callbacks=[cp], epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b779e5a1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 1. FIX: Update the filename to match the .keras extension you saved earlier\n",
    "simple_nn = load_model(\"models/simple_nn.keras\")\n",
    "\n",
    "# 2. FIX: Calculate RMSE manually since 'squared=False' was crashing earlier\n",
    "# We use np.sqrt() to convert MSE to RMSE\n",
    "train_pred = simple_nn.predict(X_train_pre)\n",
    "\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, train_pred))\n",
    "\n",
    "print(f\"Train RMSE: {train_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3b06dd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "medium_nn = Sequential()\n",
    "medium_nn.add(InputLayer(shape=(13,)))  # Explicit shape is safer\n",
    "medium_nn.add(Dense(32, activation=\"relu\"))\n",
    "medium_nn.add(Dense(16, activation=\"relu\"))\n",
    "medium_nn.add(Dense(1, activation=\"linear\"))\n",
    "\n",
    "# Note: learning_rate=.1 is very high for NNs.\n",
    "# If training is unstable, try changing this to 0.01 or 0.001\n",
    "opt = Adam(learning_rate=0.1)\n",
    "\n",
    "# FIX 1: Added .keras extension\n",
    "cp = ModelCheckpoint(\"models/medium_nn.keras\", save_best_only=True)\n",
    "\n",
    "medium_nn.compile(optimizer=opt, loss=\"mse\", metrics=[RootMeanSquaredError()])\n",
    "\n",
    "# FIX 2: Switched to validation_split since you don't have X_val/y_val\n",
    "medium_nn.fit(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    validation_split=0.2,  # Automatically uses 20% of training data for validation\n",
    "    callbacks=[cp],\n",
    "    epochs=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f65f40",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. FIX: Load the correct file format\n",
    "medium_nn = load_model(\"models/medium_nn.keras\")\n",
    "\n",
    "# 2. Predict on Training data\n",
    "train_predictions = medium_nn.predict(X_train)\n",
    "\n",
    "# 3. FIX: Calculate RMSE manually (Works on all versions)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, train_predictions))\n",
    "\n",
    "print(f\"Train RMSE: {rmse_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a702754",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "large_nn = Sequential()\n",
    "large_nn.add(InputLayer(shape=(13,)))\n",
    "large_nn.add(Dense(256, activation=\"relu\"))\n",
    "large_nn.add(Dense(128, activation=\"relu\"))\n",
    "large_nn.add(Dense(64, activation=\"relu\"))\n",
    "large_nn.add(Dense(32, activation=\"relu\"))\n",
    "large_nn.add(Dense(1, activation=\"linear\"))\n",
    "\n",
    "# CHANGE: Lowered learning rate from 0.1 to 0.001\n",
    "# 0.1 is usually too aggressive for a network this deep and will break training.\n",
    "opt = Adam(learning_rate=0.001)\n",
    "\n",
    "# FIX 1: Added .keras extension\n",
    "cp = ModelCheckpoint(\"models/large_nn.keras\", save_best_only=True)\n",
    "\n",
    "large_nn.compile(optimizer=opt, loss=\"mse\", metrics=[RootMeanSquaredError()])\n",
    "\n",
    "# FIX 2: Switched to validation_split\n",
    "large_nn.fit(x=X_train_pre, y=y_train, validation_split=0.2, callbacks=[cp], epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed294844",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. FIX: Load with the correct extension\n",
    "large_nn = load_model(\"models/large_nn.keras\")\n",
    "\n",
    "# 2. Predict on Training Data\n",
    "train_pred = large_nn.predict(X_train_pre)\n",
    "\n",
    "# 3. FIX: Calculate RMSE manually\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, train_pred))\n",
    "\n",
    "print(f\"Train RMSE: {train_rmse}\")\n",
    "\n",
    "# Note: You cannot run the second part of your code because 'X_val' is undefined.\n",
    "# To see validation performance, check the 'val_root_mean_squared_error'\n",
    "# printed in the last epoch of your .fit() output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03532927",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Gradient Boosting Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc0331b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "y_pred_test = gbr.predict(X_test_pre)\n",
    "\n",
    "# Calculate RMSE manually (Universal fix)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "\n",
    "print(\"Test RMSE:\", test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3277ca3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Large neural network on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2d16ec",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "y_pred_test = large_nn.predict(X_test_pre)\n",
    "\n",
    "# Calculate RMSE manually (Universal fix)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "\n",
    "print(\"Test RMSE:\", test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c79ae8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308f907f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Setup the output path\n",
    "output_folder = (\n",
    "    \"/home/kobey/Documents/DATASCIENCE/PROJECTS/CALIFORNIA HOUSING PRICES/data/04-predictions\"\n",
    ")\n",
    "os.makedirs(output_folder, exist_ok=True)  # Creates the folder if it doesn't exist\n",
    "\n",
    "# 2. Load your winning model\n",
    "# (Ensuring we use the correct .keras format)\n",
    "large_nn = load_model(\"models/large_nn.keras\")\n",
    "\n",
    "# 3. Generate Predictions on the Test Set\n",
    "print(\"Generating predictions...\")\n",
    "predictions = large_nn.predict(X_test_pre).flatten()  # flatten() converts shape (N,1) to (N,)\n",
    "\n",
    "# 4. Create a DataFrame to organize the results\n",
    "results_df = pd.DataFrame({\"Actual_Price\": y_test, \"Predicted_Price\": predictions})\n",
    "\n",
    "# 5. Add an 'Error' column (Difference)\n",
    "results_df[\"Error\"] = results_df[\"Actual_Price\"] - results_df[\"Predicted_Price\"]\n",
    "\n",
    "# 6. Save to CSV\n",
    "output_path = os.path.join(output_folder, \"large_nn_predictions.csv\")\n",
    "results_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Success! Predictions saved to:\\n{output_path}\")\n",
    "print(\"\\nFirst 5 rows of the output:\")\n",
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4d24b8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Predictions to submit to kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dfcb8a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Setup path\n",
    "output_folder = (\n",
    "    \"/home/kobey/Documents/DATASCIENCE/PROJECTS/CALIFORNIA HOUSING PRICES/data/04-predictions\"\n",
    ")\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# 2. Load Model\n",
    "large_nn = load_model(\"models/large_nn.keras\")\n",
    "\n",
    "# 3. Generate Predictions\n",
    "print(\"Generating predictions...\")\n",
    "predictions = large_nn.predict(X_test).flatten()\n",
    "\n",
    "# 4. Create Kaggle-Format DataFrame\n",
    "# We try to use the original index from X_test if available (standard for Pandas)\n",
    "# If X_test is a numpy array, we generate IDs starting from 0 or 1\n",
    "if hasattr(X_test, \"index\"):\n",
    "    ids = X_test.index\n",
    "else:\n",
    "    ids = range(1, len(predictions) + 1)\n",
    "\n",
    "submission_df = pd.DataFrame({\"Id\": ids, \"median_house_value\": predictions})\n",
    "\n",
    "# 5. Save\n",
    "output_path = os.path.join(output_folder, \"submission_large_nn.csv\")\n",
    "submission_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Kaggle-ready submission saved to:\\n{output_path}\")\n",
    "print(\"\\nPreview:\")\n",
    "print(submission_df.head())"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 18.5479,
   "end_time": "2026-01-15T13:46:35.432920",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-15T13:46:16.885020",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
